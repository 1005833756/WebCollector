{"name":"Webcollector","tagline":"WebCollector is an open source web crawler framework based on Java.It provides some simple interfaces for crawling the Web,you can setup a  multi-threaded web crawler in less than 5 minutes.","body":"#WebCollector\r\nWebCollector is an open source web crawler framework based on Java.It provides\r\n  some simple interfaces for crawling the Web,you can setup a\r\n  multi-threaded web crawler in less than 5 minutes.\r\n\r\n\r\n\r\n\r\n##HomePage\r\n[https://github.com/CrawlScript/WebCollector](https://github.com/CrawlScript/WebCollector)\r\n\r\n\r\n\r\n##Installation\r\nWebCollector jars are available on the [HomePage](https://github.com/CrawlScript/WebCollector).\r\n\r\n+ __webcollector-version-bin.zip__ contains core jars.\r\n\r\n+ __webcollector_example-version-bin.zip__ contains core jars with examples.\r\n\r\n##Demo\r\nLets crawl some news from yahoo.This demo prints out the titles and contents extracted from news of yahoo.\r\n\r\n[YahooCrawler.java](https://github.com/CrawlScript/WebCollector/blob/master/YahooCrawler.java):\r\n\r\n\r\n    import cn.edu.hfut.dmic.webcollector.crawler.BreadthCrawler;\r\n    import cn.edu.hfut.dmic.webcollector.model.Links;\r\n    import cn.edu.hfut.dmic.webcollector.model.Page;\r\n    import java.util.regex.Pattern;\r\n    import org.jsoup.nodes.Document;\r\n\r\n    /**\r\n     * Crawl news from yahoo news\r\n     *\r\n     * @author hu\r\n     */\r\n    public class YahooCrawler extends BreadthCrawler {\r\n\r\n        /**\r\n         * @param crawlPath crawlPath is the path of the directory which maintains\r\n         * information of this crawler\r\n         * @param autoParse if autoParse is true,BreadthCrawler will auto extract\r\n         * links which match regex rules from pag\r\n         */\r\n        public YahooCrawler(String crawlPath, boolean autoParse) {\r\n            super(crawlPath, autoParse);\r\n            /*start page*/\r\n            this.addSeed(\"http://news.yahoo.com/\");\r\n\r\n            /*fetch url like http://news.yahoo.com/xxxxx*/\r\n            this.addRegex(\"http://news.yahoo.com/.*\");\r\n            /*do not fetch url like http://news.yahoo.com/xxxx/xxx)*/\r\n            this.addRegex(\"-http://news.yahoo.com/.+/.*\");\r\n            /*do not fetch jpg|png|gif*/\r\n            this.addRegex(\"-.*\\\\.(jpg|png|gif).*\");\r\n            /*do not fetch url contains #*/\r\n            this.addRegex(\"-.*#.*\");\r\n        }\r\n\r\n        @Override\r\n        public void visit(Page page, Links nextLinks) {\r\n            String url = page.getUrl();\r\n            /*if page is news page*/\r\n            if (Pattern.matches(\"http://news.yahoo.com/.+html\", url)) {\r\n                /*we use jsoup to parse page*/\r\n                Document doc = page.getDoc();\r\n\r\n                /*extract title and content of news by css selector*/\r\n                String title = doc.select(\"h1[class=headline]\").first().text();\r\n                String content = doc.select(\"div[class=body yom-art-content clearfix]\").first().text();\r\n\r\n                System.out.println(\"URL:\\n\" + url);\r\n                System.out.println(\"title:\\n\" + title);\r\n                System.out.println(\"content:\\n\" + content);\r\n\r\n                /*If you want to add urls to crawl,add them to nextLink*/\r\n                /*WebCollector automatically filters links that have been fetched before*/\r\n                /*If autoParse is true and the link you add to nextLinks does not match the regex rules,the link will also been filtered.*/\r\n                // nextLinks.add(\"http://xxxxxx.com\");\r\n            }\r\n        }\r\n\r\n        public static void main(String[] args) throws Exception {\r\n            YahooCrawler crawler = new YahooCrawler(\"crawl\", true);\r\n            crawler.setThreads(50);\r\n            crawler.setTopN(100);\r\n            //crawler.setResumable(true);\r\n            /*start crawl with depth of 4*/\r\n            crawler.start(4);\r\n        }\r\n\r\n    }\r\n\r\n\r\n\r\n\r\n###Other Documentation\r\n\r\n+ [中文文档](https://github.com/CrawlScript/WebCollector/blob/master/README.zh-cn.md)\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}